{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Part3Header"
   },
   "source": [
    "**PART 3**\n",
    "\n",
    "**ADVANCED DEEP NETWORKS FOR COMPLEX PROBLEMS**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chap14Header"
   },
   "source": [
    "**CHAPTER 14 - TensorBoard: Big brother of TensorFlow**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sec14_1"
   },
   "source": [
    "### **14.1 Visualize data with TensorBoard**\n",
    "\n",
    "TensorBoard is a comprehensive visualization toolkit included with TensorFlow. It acts as a vital companion to the framework, enabling practitioners to visualize high-dimensional data (such as images and text), track and monitor model metrics (like loss and accuracy) in real-time, and profile models to identify performance bottlenecks. It operates by reading event files from a designated logging directory and displaying them on a web-based dashboard.\n",
    "\n",
    "**Scenario**: As a data scientist at a fashion company, you are tasked with building a model to identify clothing items. You select the **Fashion-MNIST** dataset for this task, which consists of grayscale images of 10 clothing categories. Before training, inspecting the data is crucial to ensure it is loaded correctly and that labels match the images. Visualizing raw data helps verify the integrity of the input pipeline.\n",
    "\n",
    "**Data Loading**: We download the Fashion-MNIST dataset using `tensorflow_datasets` and process it into training, validation, and test sets. We create a pipeline that shuffles the data and batches it.\n",
    "\n",
    "**Logging Images**: To visualize images, we use the `tf.summary.image()` function. This involves creating a `tf.summary.SummaryWriter` that points to a specific log directory. We typically include a timestamp in the directory name to distinguish between different runs. The writer is used within a context manager (`with image_writer.as_default():`) to log specific batches of images.\n",
    "\n",
    "![Figure 14.1 Jupyter magic commands in a notebook cell](./14.Chapter-14/Figure14-1.jpg)\n",
    "![Figure 14.2 The TensorBoard visualizing logged images, displayed inline in the Jupyter notebook](./14.Chapter-14/Figure14-2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Code_VisData"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Define log directory with timestamp format YYYYMMDDHHMMSS\n",
    "log_datetimestamp_format = \"%Y%m%d%H%M%S\"\n",
    "log_datetimestamp = datetime.strftime(datetime.now(), log_datetimestamp_format)\n",
    "image_logdir = \"./logs/data_{}/train\".format(log_datetimestamp)\n",
    "\n",
    "# Create file writer\n",
    "image_writer = tf.summary.create_file_writer(image_logdir)\n",
    "\n",
    "# Log images\n",
    "with image_writer.as_default():\n",
    "    # Iterate through the dataset and write images using tf.summary.image\n",
    "    # We can write individual images or batches. 'max_outputs' limits how many are stored.\n",
    "    # for data in fashion_ds[\"train\"].batch(1).take(10):\n",
    "    #     tf.summary.image(id2label_map[int(data[\"label\"].numpy())], data[\"image\"], step=0)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sec14_2"
   },
   "source": [
    "### **14.2 Tracking and monitoring models with TensorBoard**\n",
    "\n",
    "A primary use of TensorBoard is monitoring the training progress of deep learning models. Deep networks often take a long time to train, and waiting until the end to discover a failure is inefficient. By visualizing metrics like loss and accuracy in real-time, you can quickly identify if a model is failing to converge or overfitting, allowing you to stop training early and save time.\n",
    "\n",
    "We compare two models on the Fashion-MNIST dataset:\n",
    "1.  **Fully Connected Network (Dense)**: A simple Multilayer Perceptron with dense layers.\n",
    "2.  **Convolutional Neural Network (CNN)**: A network using Conv2D and Pooling layers, which is generally better suited for image tasks as it captures spatial hierarchies.\n",
    "\n",
    "**Organizing Runs**: To compare these models effectively, we save their logs to separate subdirectories (e.g., `./logs/dense/run_1` vs `./logs/conv/run_1`). TensorBoard treats each subdirectory as a separate \"run\" and allows you to toggle them on and off for comparison. A robust naming convention usually includes the model type and a timestamp.\n",
    "\n",
    "**The TensorBoard Callback**: In Keras, we use the `tf.keras.callbacks.TensorBoard` callback. Important arguments include:\n",
    "* `log_dir`: The path where log files will be written.\n",
    "* `histogram_freq`: How often (in epochs) to compute activation and weight histograms. This helps analyze the distribution of values within layers.\n",
    "* `write_graph`: Whether to visualize the model's computation graph (defaults to True).\n",
    "* `profile_batch`: Which batches to capture for performance profiling (discussed later).\n",
    "\n",
    "![Figure 14.3 How tracked metrics are displayed on the TensorBoard](./14.Chapter-14/Figure14-3.jpg)\n",
    "\n",
    "The scalar dashboard plots metrics over time. You can use the smoothing slider to eliminate noise and see global trends. You can also toggle between linear and log scales for the y-axis.\n",
    "\n",
    "![Figure 14.4 How the smoothing parameter changes the line plot](./14.Chapter-14/Figure14-4.jpg)\n",
    "![Figure 14.5 Viewing metrics of both the dense model and the convolutional model](./14.Chapter-14/Figure14-5.jpg)\n",
    "\n",
    "**Activation Histograms**: TensorBoard can display histograms of the weights and activations of your model layers over time. This helps diagnose issues like vanishing gradients (activations becoming zero) or exploding gradients (activations growing too large). Histograms from different epochs are stacked, with darker colors representing more recent epochs.\n",
    "\n",
    "![Figure 14.6 Activation histograms displayed by the TensorBoard](./14.Chapter-14/Figure14-6.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Code_TBCallback"
   },
   "outputs": [],
   "source": [
    "# Define TensorBoard callback for the Dense model\n",
    "dense_log_dir = \"logs/dense_{}\".format(log_datetimestamp)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=dense_log_dir,\n",
    "    histogram_freq=1,  # Log histograms every epoch to visualize weight distributions\n",
    "    profile_batch=0    # Disable profiling for this specific run\n",
    ")\n",
    "\n",
    "# Model training would look like this:\n",
    "# dense_model.fit(tr_ds, validation_data=v_ds, epochs=10, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sec14_3"
   },
   "source": [
    "### **14.3 Using tf.summary to write custom metrics during model training**\n",
    "\n",
    "While Keras provides standard metrics (accuracy, loss), research often requires tracking custom values that are not part of the standard set. For instance, you might want to analyze the stability of your layer weights by tracking their mean and standard deviation during training to see the effect of Batch Normalization.\n",
    "\n",
    "Since these aren't standard Keras metrics that can be passed to `model.compile`, we implement a **custom training loop**. This gives us granular control over the training process and logging.\n",
    "\n",
    "1.  **Define Models**: We define two versions of the model: one with `BatchNormalization` layers and one without, to compare their weight statistics.\n",
    "2.  **Custom Loop**: We use `tf.summary.create_file_writer` to instantiate a writer. Inside the training loop (iterating over epochs and batches), we manually calculate the metrics.\n",
    "3.  **Log Scalars**: We use `tf.summary.scalar()` to log the calculated mean and standard deviation of the weights at specific steps. It is important to call `writer.flush()` to ensure data is written to the disk buffer immediately.\n",
    "\n",
    "The visualization in TensorBoard allows us to see that with Batch Normalization, the mean and standard deviation of weights vary much more compared to when it is not used, providing insight into how normalization affects internal layer statistics.\n",
    "\n",
    "![Figure 14.8 The mean and standard deviation of weights plotted in the TensorBoard](./14.Chapter-14/Figure14-8.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Code_CustomMetrics"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_model(model, dataset, log_dir, log_layer_name, epochs):\n",
    "    # Create a summary writer for the custom log directory\n",
    "    writer = tf.summary.create_file_writer(log_dir)\n",
    "    step = 0\n",
    "    \n",
    "    # Use the writer context manager\n",
    "    with writer.as_default():\n",
    "        for e in range(epochs):\n",
    "            for batch in dataset:\n",
    "                # Perform training step here (e.g., model.train_on_batch)\n",
    "                # ...\n",
    "                \n",
    "                # Extract weights from the specific layer we want to analyze\n",
    "                weights = model.get_layer(log_layer_name).get_weights()[0]\n",
    "                \n",
    "                # Log custom metrics using tf.summary.scalar\n",
    "                tf.summary.scalar(\"mean_weights\", np.mean(np.abs(weights)), step=step)\n",
    "                tf.summary.scalar(\"std_weights\", np.std(np.abs(weights)), step=step)\n",
    "                \n",
    "                writer.flush()\n",
    "                step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sec14_4"
   },
   "source": [
    "### **14.4 Profiling models to detect performance bottlenecks**\n",
    "\n",
    "TensorBoard Profiler is a powerful tool to analyze where your model spends its time during execution (e.g., is it waiting for data? is the GPU idle? is the kernel launch slow?). Identifying these bottlenecks is the first step toward optimization.\n",
    "\n",
    "**Prerequisites**: You need to install the `tensorboard_plugin_profile` package and the NVIDIA CUDA Profiling Toolkit Interface (`libcupti`). On Windows, this often requires specific configuration, such as copying DLLs to the CUDA bin folder and enabling GPU performance counters for all users in the NVIDIA Control Panel.\n",
    "\n",
    "**Running the Profiler**: We enable profiling by passing the `profile_batch` argument to the TensorBoard callback. For example, `profile_batch=[10, 20]` tells TensorFlow to profile batches 10 through 20. TensorBoard generates a report with a performance summary, step-time graph, and specific recommendations.\n",
    "\n",
    "![Figure 14.10 TensorBoard profiling interface](./14.Chapter-14/Figure14-10.jpg)\n",
    "\n",
    "#### **Optimizing the input pipeline**\n",
    "If the profiler shows high \"Input Time,\" it means the GPU is starving for data because the CPU cannot prepare batches fast enough. We can optimize the `tf.data` pipeline:\n",
    "1.  **Parallel Mapping**: Use `num_parallel_calls=tf.data.AUTOTUNE` in the `map` function. This tells TensorFlow to use multiple threads to process data transformations in parallel.\n",
    "2.  **Prefetching**: Add `.prefetch(tf.data.experimental.AUTOTUNE)` at the end of the pipeline. This allows the CPU to prepare the next batch of data while the GPU is currently processing the previous batch, effectively overlapping preprocessing and model execution.\n",
    "3.  **Kernel Launch Latency**: If the CPU is too busy to launch GPU kernels in time (high Kernel Launch time), we can set the environment variable `TF_GPU_THREAD_MODE=gpu_private`. This dedicates specific threads solely for launching GPU kernels, preventing them from being blocked by other CPU tasks.\n",
    "\n",
    "![Figure 14.11 Side-by-side comparison of the profiling overview with and without data- and model-related optimizations](./14.Chapter-14/Figure14-11.jpg)\n",
    "\n",
    "#### **Mixed precision training**\n",
    "Standard training uses 32-bit floating-point numbers (`float32`). This is memory-intensive and slower on modern GPUs equipped with Tensor Cores. **Mixed Precision Training** uses 16-bit floats (`float16`) for operations (like matrix multiplications) while keeping variables (weights) in `float32` for numerical stability. This speeds up math significantly and reduces memory usage, often allowing for larger batch sizes.\n",
    "\n",
    "TensorBoard's memory profile view allows verifying the reduction in memory consumption when switching to mixed precision.\n",
    "\n",
    "![Figure 14.12 Memory profile with and without the optimizations](./14.Chapter-14/Figure14-12.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Code_MixedPrecision"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Enable mixed precision training globally\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Optimized Data Pipeline Example\n",
    "# dataset = dataset.map(get_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sec14_5"
   },
   "source": [
    "### **14.5 Visualizing word vectors with the TensorBoard**\n",
    "\n",
    "Visualizing embeddings is crucial in NLP to verify if the model has learned semantic relationships (e.g., ensuring \"cat\" is closer to \"dog\" than to \"car\"). TensorBoard's **Embedding Projector** allows us to visualize high-dimensional vectors in 2D or 3D space.\n",
    "\n",
    "**Process**:\n",
    "1.  **Load Vectors**: We load pretrained word vectors (like **GloVe**) into a pandas DataFrame. These vectors capture semantic meaning based on co-occurrence statistics.\n",
    "2.  **Save Checkpoint**: The embeddings must be saved as a `tf.Variable` within a TensorFlow checkpoint file (`.ckpt`). This is the format TensorBoard reads.\n",
    "3.  **Save Metadata**: To label the points in the visualization, we save a tab-separated value (TSV) file containing the words corresponding to each vector row.\n",
    "4.  **Configure Projector**: We use `tensorboard.plugins.projector` to write a configuration file (`projector_config.pbtxt`) that links the checkpoint to the metadata file.\n",
    "\n",
    "TensorBoard provides algorithms like **PCA** (Principal Component Analysis), **t-SNE**, and **UMAP** to project these high-dimensional embeddings into 2D or 3D space. The interface allows searching for specific words using regular expressions to highlight clusters and verify semantic relationships.\n",
    "\n",
    "![Figure 14.13 The word vector view on the TensorBoard](./14.Chapter-14/Figure14-13.jpg)\n",
    "![Figure 14.14 Searching words in the visualizations](./14.Chapter-14/Figure14-14.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Code_Embeddings"
   },
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector\n",
    "import os\n",
    "\n",
    "def visualize_embeddings(log_dir, embeddings_df):\n",
    "    # 1. Create Variable and Save Checkpoint\n",
    "    # Convert dataframe values to a TensorFlow variable\n",
    "    weights = tf.Variable(embeddings_df.values)\n",
    "    checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "    # 2. Save Metadata (Labels)\n",
    "    # Write the words (index of dataframe) to a TSV file\n",
    "    with open(os.path.join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "        for w in embeddings_df.index:\n",
    "            f.write(w + '\\n')\n",
    "\n",
    "    # 3. Configure Projector\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    # The tensor name usually follows a specific pattern in the checkpoint\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = 'metadata.tsv'\n",
    "    \n",
    "    # Write the config file for TensorBoard\n",
    "    projector.visualize_embeddings(log_dir, config)"
   ]
  }
 ]
}